{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4beac401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"\")\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "import torch\n",
    "# from models.yolo import Model\n",
    "model=DetectionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680f822",
   "metadata": {},
   "source": [
    "## Convert VBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "cfg = r\"ultralytics\\cfg\\models\\VBM\\VBM_YOLO.yaml\"\n",
    "model = model(cfg, ch=3, nc=6)\n",
    "#model = model.half()\n",
    "model = model.to(device)\n",
    "_ = model.eval()\n",
    "ckpt = torch.load(r\"\", map_location='cpu') # VBM_AGB *.pt\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "for k, v in model.state_dict().items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2de7e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    注意 1.idx < 31  2.\"model.{}.cv4.\" \"model.{}.cv5.\" \"model.{}.dfl2.\"   3. idx+23\n",
    "idx = 0\n",
    "for k, v in model.state_dict().items():\n",
    "    if \"model.{}.\".format(idx) in k:\n",
    "        if idx < 31:\n",
    "            kr = k.replace(\"model.{}.\".format(idx), \"model.{}.\".format(idx+1))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "        elif \"model.{}.cv2.\".format(idx) in k:\n",
    "            kr = k.replace(\"model.{}.cv2.\".format(idx), \"model.{}.cv4.\".format(idx+23))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "        elif \"model.{}.cv3.\".format(idx) in k:\n",
    "            kr = k.replace(\"model.{}.cv3.\".format(idx), \"model.{}.cv5.\".format(idx+23))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "        elif \"model.{}.dfl.\".format(idx) in k:\n",
    "            kr = k.replace(\"model.{}.dfl.\".format(idx), \"model.{}.dfl2.\".format(idx+23))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "    else:\n",
    "        while True:\n",
    "            idx += 1\n",
    "            if \"model.{}.\".format(idx) in k:\n",
    "                break\n",
    "        if idx < 31:\n",
    "            kr = k.replace(\"model.{}.\".format(idx), \"model.{}.\".format(idx+1))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "        elif \"model.{}.cv2.\".format(idx) in k:\n",
    "            kr = k.replace(\"model.{}.cv2.\".format(idx), \"model.{}.cv4.\".format(idx+23))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "        elif \"model.{}.cv3.\".format(idx) in k:\n",
    "            kr = k.replace(\"model.{}.cv3.\".format(idx), \"model.{}.cv5.\".format(idx+23))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "        elif \"model.{}.dfl.\".format(idx) in k:\n",
    "            kr = k.replace(\"model.{}.dfl.\".format(idx), \"model.{}.dfl2.\".format(idx+23))\n",
    "            model.state_dict()[k] -= model.state_dict()[k]\n",
    "            model.state_dict()[k] += ckpt['model'].state_dict()[kr]\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "960796e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ckpt = {'model': model.half(),\n",
    "          'optimizer': None,\n",
    "          'best_fitness': None,\n",
    "          'ema': None,\n",
    "          'updates': None,\n",
    "          'opt': None,\n",
    "          'git': None,\n",
    "          'date': None,\n",
    "          'epoch': -1}\n",
    "torch.save(m_ckpt, \"./VBM_converted.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
